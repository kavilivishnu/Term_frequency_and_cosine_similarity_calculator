{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75af41cc",
   "metadata": {},
   "source": [
    "## a) Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "09fbeb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0d3edb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = [] # Since we are using binary entries, we have to keep track of already visited words\n",
    "vectorForPara = [] # Final \"Vector\" which has all the binary information of the occurances stored in it\n",
    "def vectorize(sentence, word): # This function is responsible to build the term frequency vector.\n",
    "    countIdx = 0 # This counter will help us to carryon with the loop, or append \"0\". We use this index when \n",
    "    # we have a \"pass case\", and have to compare our \"list of to be compared terms\" to the \"terms in the sentence or phrase\",\n",
    "    # which might come bit late or even towards the end of the given sentence, Eg: the term pattern(s) when serached in \"Para2\"\n",
    "    splitSentence = sentence.split(' ') # Splitting the document to individual terms, to make comparisons easy\n",
    "    for char in splitSentence: # Loop starts(Iterate through each tem in a sentence)\n",
    "        if('(s)' in word): # Conditional operation when formatted \"list of to be compared terms\" are given\n",
    "            stripOffS = word.strip('(s)') # Removing the formatting initialy for easy comparison\n",
    "            addPlural = stripOffS+'s'# Appending the variable that was \"Stripped off\" in the earlier step\n",
    "            if (stripOffS not in visited and ((char.lower() == stripOffS) or (char.lower() == addPlural))): \n",
    "                # Case where, 1) The term is encountered for the first time.\n",
    "                # 2) Either of the singular or plural term is present, that matches with the given words in the document.\n",
    "                vectorForPara.append(1) # push the binary \"1\", which indicates \"true\" if the match is found\n",
    "            else: # This scope is for the terms which we have to check if are there in sentence or not. This condition is solely\n",
    "                  # for the terms which doesn't come early in the sentence.\n",
    "                countIdx = countIdx + 1\n",
    "                if (countIdx != len(splitSentence)): # We continue checking until we reach the last letter in the document that was split earlier\n",
    "                    continue\n",
    "                else:\n",
    "                    vectorForPara.append(0) # Once we go beyond length, and haven't found any match till now, pushing the binary that is \"0\"\n",
    "        elif(word == char and char not in visited): # If the variable does not have any formatting, then we simple search the equality constant\n",
    "            vectorForPara.append(1) # If satisfied, 1 is sent to out vector array\n",
    "        else:\n",
    "            if(word not in splitSentence): # This will be the case that only get's fired when the variable won't be able to find itself in the document.\n",
    "                # That is reason it is at the end of the fucntion\n",
    "                vectorForPara.append(0) # If the condition satisfies, we push the binary \"0\", which means, \"No match found\"\n",
    "                break; # We break out of the loop\n",
    "        visited.append(char.lower()) # After every iteration we keep pushing the encountered data. We do this as out implementation\n",
    "                                     # inorder to skip through the duplicates.\n",
    "    return vectorForPara # Finaly we return the \"term vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0a0913ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para1 -  [1, 1, 1, 1, 1, 1, 0] Para2 -  [1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "para1 = \"Machine learning algorithms can be applied on Ilot to reap the rewards of cost savings, improved time, and performance. In the recent era we all have experienced the benefits of machinelearning techniques from streaming movie services that recommend titles to watch based on viewing habits to monitor fraudulent activity based on spending pattern of the customers. It can handle large and complex information to draw interesting patterns or trends in them such as anomalies. Machines are needed to process information fast and make decisions when it reaches the threshold.\"\n",
    "para2 = \"Machine learning is here. Artificial intelligence is here. We are right in. the midst of the information revolution and while it's an incredible time and place to be in, one must be wary of the implications that come along with it. Having a machine tell you how long your commute will be, what music you should listen to, and what content you would likely engage with are all relatively harmless examples. But while you're scrolling through your Facebook newsfeed, an algorithm somewhere is used to make decisions about someone's medical diagnoses, their parole eligibility, or their career prospects.\"\n",
    "\n",
    "tobeCompared=['machine(s)', 'information','algorithm(s)', 'learning', 'decision(s)', 'pattern(s)', 'revolution']\n",
    "\n",
    "vectorOfPara1 = []\n",
    "vectorOfPara2 = []\n",
    "\n",
    "for word in tobeCompared:\n",
    "    vectorize(para1, word)\n",
    "    visited = []\n",
    "        \n",
    "for word in tobeCompared:\n",
    "    vectorize(para2, word)\n",
    "    visited = []\n",
    "            \n",
    "if(len(vectorForPara) == 14):\n",
    "    # Here we split the data of documents that came combined from previous functions\n",
    "    vectorOfPara1 = vectorForPara[:len(vectorForPara)//2]\n",
    "    vectorOfPara2 = vectorForPara[len(vectorForPara)//2:]\n",
    "else: print('re-run 1st cell, then run this cell')\n",
    "    \n",
    "print('Para1 - ', vectorOfPara1, 'Para2 - ',  vectorOfPara2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e2c39",
   "metadata": {},
   "source": [
    "## b) Cosine-similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "deb48756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 / 5.000000000000001 => 0.9999999999999998\n",
      "The Cosine-Similarity between the PARAGRAPH-1 and PARAGRAPH-2 is 99.99999999999997 %\n",
      "Vector of PARAGRAPH-1 => [1, 1, 1, 1, 1, 1, 0]\n",
      "Vector of PARAGRAPH-2 => [1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# This whole cell is about the MATHEMATICAL function that helps us solve the Cosine Similarity of the given documents\n",
    "collectedValues = {}\n",
    "\n",
    "def squareofIndividualDigitsofPara1(vectorArray):\n",
    "    lengthOfVector1 = -1\n",
    "    for num in vectorArray:\n",
    "        lengthOfVector1 = (num ** 2) + lengthOfVector1\n",
    "    return lengthOfVector1\n",
    "    \n",
    "\n",
    "def squareofIndividualDigitsofPara2(vectorArray):\n",
    "    lengthOfVector2 = -1\n",
    "    for num in vectorArray:\n",
    "        lengthOfVector2 = (num ** 2) + lengthOfVector2\n",
    "    return lengthOfVector2\n",
    "\n",
    "\n",
    "def coreCalculationofCosineSimilarity(doc1, doc2):\n",
    "    cosineSimilarity = 0\n",
    "    dotProduct = -1\n",
    "    productOfLengthOfVectors = 0\n",
    "    index = -1\n",
    "    if(len(doc1) != 0 and len(doc2) != 0):\n",
    "        for termofDoc1 in doc1:\n",
    "            dotProduct = ((termofDoc1 * doc2[index]) + dotProduct)\n",
    "            productOfLengthOfVectors = (math.sqrt(squareofIndividualDigitsofPara1(doc1)) * math.sqrt(squareofIndividualDigitsofPara2(doc2)))\n",
    "        cosineSimilarity = dotProduct / productOfLengthOfVectors\n",
    "        index = index + 1\n",
    "    else:\n",
    "        print('Please run the above cells to run this cell')\n",
    "    collectedValues = { \n",
    "        'dotProduct': dotProduct, \n",
    "        'productOfLengthOfVectors': productOfLengthOfVectors,\n",
    "        'contentsofProductOfLengthOfVectors': {\n",
    "            'doc1': doc1,\n",
    "            'doc2': doc2,\n",
    "            'squareofIndividualDigitsofPara1': squareofIndividualDigitsofPara1(doc1),\n",
    "            'squareofIndividualDigitsofPara2': squareofIndividualDigitsofPara1(doc2),\n",
    "            'squareROOTofSquareofIndividualDigitsofPara1': math.sqrt(squareofIndividualDigitsofPara1(doc1)),\n",
    "            'squareROOTofSquareofIndividualDigitsofPara2': math.sqrt(squareofIndividualDigitsofPara2(doc2)),  \n",
    "        },\n",
    "        'cosineSimilarity': cosineSimilarity,\n",
    "    }\n",
    "    return collectedValues\n",
    "\n",
    "parametersOfCosineSimilarityofPara1AndPara2 = coreCalculationofCosineSimilarity(vectorOfPara1, vectorOfPara2)\n",
    "\n",
    "print(f\"{parametersOfCosineSimilarityofPara1AndPara2['dotProduct']} / {parametersOfCosineSimilarityofPara1AndPara2['productOfLengthOfVectors']} => {parametersOfCosineSimilarityofPara1AndPara2['cosineSimilarity']}\")\n",
    "\n",
    "print('The Cosine-Similarity between the PARAGRAPH-1 and PARAGRAPH-2 is', parametersOfCosineSimilarityofPara1AndPara2['cosineSimilarity']*100,'%')\n",
    "print(f\"Vector of PARAGRAPH-1 => {vectorOfPara1}\")\n",
    "print(f\"Vector of PARAGRAPH-2 => {vectorOfPara2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e5bb5",
   "metadata": {},
   "source": [
    "## c) Cosine-similarity between the Para1 itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d3a05323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 / 86.0 => 1.0\n",
      "The Cosine-Similarity between the PARAGRAPH-1 and ITSELF is 100.0 %\n",
      "Vector of PARAGRAPH-1 and ITSELF => [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "visited = []\n",
    "vectorForParaItself = []\n",
    "def createVector(tobeComparedByItself, word):\n",
    "    countIdx = 0\n",
    "    for char in tobeComparedByItself:\n",
    "        if('(s)' in word):\n",
    "            stripOffS = word.strip('(s)')\n",
    "            addPlural = stripOffS+'s'\n",
    "            if (stripOffS not in visited and ((char.lower() == stripOffS) or (char.lower() == addPlural))):\n",
    "                vectorForParaItself.append(1)\n",
    "            else:\n",
    "                countIdx = countIdx + 1\n",
    "                if (countIdx != len(tobeComparedByItself)): \n",
    "                    continue\n",
    "                else:\n",
    "                    vectorForParaItself.append(0)\n",
    "        elif(word == char and char not in visited):\n",
    "            vectorForParaItself.append(1)\n",
    "        else:\n",
    "            if(word not in tobeComparedByItself):\n",
    "                vectorForParaItself.append(0)\n",
    "                break;\n",
    "        visited.append(char.lower())\n",
    "    return vectorForParaItself\n",
    "    \n",
    "    \n",
    "\n",
    "tobeComparedByItself = para1.split(' ')\n",
    "\n",
    "for word in tobeComparedByItself:\n",
    "    createVector(tobeComparedByItself, word)\n",
    "    visited = []\n",
    "    \n",
    "parametersOfCosineSimilarityofPara1AndItself = coreCalculationofCosineSimilarity(vectorForParaItself, vectorForParaItself)\n",
    "\n",
    "print(f\"{parametersOfCosineSimilarityofPara1AndItself['dotProduct']} / {parametersOfCosineSimilarityofPara1AndItself['productOfLengthOfVectors']} => {parametersOfCosineSimilarityofPara1AndItself['cosineSimilarity']}\")\n",
    "\n",
    "print('The Cosine-Similarity between the PARAGRAPH-1 and ITSELF is', parametersOfCosineSimilarityofPara1AndItself['cosineSimilarity']*100,'%')\n",
    "print(f\"Vector of PARAGRAPH-1 and ITSELF => {vectorForParaItself}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8d03e5",
   "metadata": {},
   "source": [
    "### The function - \"parametersOfCosineSimilarityofPara1AndItself()\", which has returned the output that is \n",
    "\n",
    "### shown in the above cell, itself is a proof that: When we find the \"Cosine-Smiliarity\" between \"SIMILAR\" \n",
    "\n",
    "### documents,  the angle between the two vectors will be 0°. Now, if we subsitute that as \"θ\" of Cos, => Cos(θ) \n",
    "\n",
    "### => Cos(0°), which is equal to \"1\". We found the same by solving the \"Cosine-Similarity\", linear Algebraically.  \n",
    "\n",
    "### So, therefore, if we find the \"Similarity Percent\" between PARAGRAPH - 1 and itself we get 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb970aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
